---
layout: event
title: "Allegro Tech Live #7 - BigData"
time: 1589385600000
venue_address_1: 
venue_city: 
venue_name: Online event
status: past
id: 270525480
registration: 
---

<p>Allegro Tech Live to nowa (w 100% zdalna) odsłona naszych stacjonarnych meetupów Allegro Tech Talks. Zazwyczaj spotykaliśmy się w naszych biurach, ale tym razem to my zagościmy u Was :)<br />A więc usiądźcie wygodnie na kanapie, zaopatrzcie się w ulubiony napój i odpalcie nasz live stream. Widzimy się na czacie!</p>
<p>Data:[masked]<br />Miejsce: ZDALNIE (live stream pojawi się w chwili rozpoczęcia na kanale: <a href="https://www.facebook.com/allegro.tech/" class="linkified">https://www.facebook.com/allegro.tech/</a>)<br />Godz: 18:00 - 20:00</p>
<p>AGENDA<br />18:00 - 18:10 - Rozpoczęcie<br />18:30 - 19:00 - Przetwarzania Realtime na Google Cloud Platform z wykorzystaniem Apache Beam - Marcin Kuthan<br />19:05 - 19:35 - Big challenges in the world of data - Dariusz Eliasz</p>
<p>OPIS<br />1. Przetwarzania Realtime na GCP z wykorzystaniem Apache Beam - Marcin Kuthan (Allegro)</p>
<p>Podczas jednego z poprzednich wystąpień w ramach “Allegro Tech talks” (<a href="https://youtu.be/ALDx__TGT70" class="embedded">https://youtu.be/ALDx__TGT70</a>) opowiadałem o przetwarzaniach realtime opartych o Kafka Streams, Spark, Druid i Turnilo uruchamianych w data centers Allegro. Pod koniec prezentacji wspomniałem o nowym projekcie realizowanym w oparciu o technologie publicznej chmury i właśnie przyszedł czas żeby podzielić się z Wami nowymi doświadczeniami.</p>
<p>Tematem rozmowy będą ponownie przetwarzania realtime, ale tym razem oparte o technologie dostępne wyłącznie w chmurze Google-a: PubSub, Dataflow i BigQuery. Dowiecie się jak za ich pomocą zrealizowaliśmy projekt analityki do automatyzacji treści, która jest wyświetlana na stronach Allegro, a wkrótce trafi też do naszych aplikacji mobilnych.</p>
<p>Marcin Kuthan - inżynier BigData, lider jednego z zespołów tworzących platformę analityczną Allegro. Brał aktywny udział w produkcyjnym wdrożeniu przetwarzań realtime opartych o Spark Streaming, Kafka Streams a ostatnio Apache Beam. Poza zagadnieniami “backend” rozwija Turnilo (<a href="https://github.com/allegro/turnilo" class="linkified">https://github.com/allegro/turnilo</a>) ponieważ jest przekonany, że nawet cenne dane są niewiele warte bez ich dobrej prezentacji.</p>
<p>2. Big challenges in the world of data - Darek Eliasz (Allegro)</p>
<p>Tematem rozmowy będą wyzwania jakie przed organizacjami takimi jak Allegro stawia przetwarzanie danych. Wolumeny przetwarzanych danych rosną nieliniowo, a sposoby konsumpcji danych dawno wykroczyły poza świat raportów i dashboardów. Dzisiaj to funkcjonalności oparte o dane są głównym motorem napędowym rozwoju platform przetwarzania danych - popularyzacja ML stawia coraz wyższe wymagania co do szybkości, elastyczności i jakości ekosystemu przetwarzania danych. O tych wyzwaniach i o tym jak sobie z nimi radzimy w Allegro opowiem w swojej prezentacji.</p>
<p>Darek Eliasz - główne zainteresowania to architektura rozwiązań big data i data governance. Entuzjasta skalowalnych rozwiązań rozproszonych, przetwarzania dużych zbiorów danych i ciągłego szukania ulepszeń.</p>
<p>Zapraszamy również do dołączenia do wydarzenia na FB:<br /><a href="https://www.facebook.com/events/643206099794352/" class="linkified">https://www.facebook.com/events/643206099794352/</a></p>
